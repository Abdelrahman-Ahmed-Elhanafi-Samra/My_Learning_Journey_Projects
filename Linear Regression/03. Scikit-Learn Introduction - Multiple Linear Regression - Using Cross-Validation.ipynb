{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89f61514",
   "metadata": {},
   "source": [
    "<img src=\"./files/Multiple Linear Regression using cross validation.png\"\n",
    "     alt=\"Multiple Linear Regression using cross validation\"\n",
    "     style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10af832",
   "metadata": {},
   "source": [
    "____________________________________________________________________________________________________\n",
    "# <center><span style=\"color:Purple\">Hello this is, *Multiple Linear Regression using Cross Validation*</span>. ü§ñüíª\n",
    "____________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d5b3ed",
   "metadata": {},
   "source": [
    "## Setting Up the Working Environment üõ†Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b98913d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d4935",
   "metadata": {},
   "source": [
    "## Importing Datasets üìñ\n",
    "\n",
    "```python\n",
    "from sklearn import datasets\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7192014f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "# ---------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae0f336",
   "metadata": {},
   "source": [
    "## The Working Dataset üîé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae5d63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting X and y\n",
    "X = load_boston().data\n",
    "y = load_boston().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0687356",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transeform X into dataframe\n",
    "boston = pd.DataFrame(X, columns = load_boston().feature_names)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149c8254",
   "metadata": {},
   "source": [
    "## K-fold Cross Validation\n",
    "\n",
    "**Why Cross Validation?**\n",
    "\n",
    "You may have noticed that __train/test split__ technique has some pitfalls or drawbacks such as: \n",
    "  \n",
    "  - In case of a small data set, only a subset of observations are used to train the model. Which might not be enough to capture all the variations in the data. \n",
    "  \n",
    "  - The metric used to measure the model performance is based on the test set, which suffers from:\n",
    "      - **High variability**: whenever we split the data again, the metric will change, because it depends on the observations in test set.\n",
    "      - **Less generalizibility**: If the test set has peculiarities of outliers, that will affect the metric used, which will not make it a good metric to generalize on unseen data.\n",
    "      \n",
    "Thus, relying on the metric computed from the test set maybe misleading. For this reason we had to search for another technique.\n",
    "\n",
    "**Can we overcome these pitfalls?**\n",
    "\n",
    "**Cross Validation** comes to correct the **train/test split** technique problems. \n",
    "\n",
    "## Cross Validation \n",
    "\n",
    "- In cross validation there are many training/validation splits, not just one.\n",
    "\n",
    "- Cross validation gives us the chance train and assess the model various times on training/validation combinations.\n",
    "\n",
    "- Running and testing a model several times make our **metrics more reliable**.\n",
    "\n",
    "\n",
    "### The Methodology of K-fold Cross Validation\n",
    "\n",
    "  1. Split the data set randomly into K folds (groups) (5-fold or 10-fold are common splits)\n",
    "  \n",
    "  2. Train the model on **K-1** folds, and test the model on the left one, then compute the desired metric. \n",
    "  \n",
    "  3. Repeat step two untill all folds are used as a test set. \n",
    "  \n",
    "  4. Compute the average of the computed metric from each step. \n",
    "  \n",
    "### Advantages of Cross Validation\n",
    "  \n",
    "- If we split our data into 80% training and 20% validation set; in each iteration, a 80% of the data is used to train the model, and 20% is used to validate the model. \n",
    "\n",
    "- This technique allows us to use all of the data to be use only once to validate the model. This ensures that every point is used for validation exactly one time. \n",
    "\n",
    "- Ensuring using each point in the validation set only once is not required (Bootstrapping can be used, but in practice, they have been proved to give similar results).\n",
    "  \n",
    "#### Note: \n",
    "\n",
    "  - If we split the the data into 5, we say 5-Fold CV\n",
    "  - If we split the the data into 10, we say 10-Fold CV, and so on. \n",
    "  \n",
    "#### 5-Fold CV Example:\n",
    "\n",
    "1. If R^2 is the metric\n",
    "\n",
    " $$R^{2} = \\frac {1}{K} \\sum_{i=1}^{K} R^{2}_{i}$$\n",
    "\n",
    "2. If MSE (Mean Squared Error) is the metric\n",
    "\n",
    " $$MSE = \\frac {1}{K} \\sum_{i=1}^{K} MSE_{i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979d4b7f",
   "metadata": {},
   "source": [
    "<img src=\"./files/K-fold.png\"\n",
    "     alt=\"ML process\"\n",
    "     style=\"float: left; margin-right: 10px;\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7decefe9",
   "metadata": {},
   "source": [
    "## Performing Cross Validation Manually Using KFold() Function\n",
    "\n",
    "- `sk-learn` provides us with a function called `KFold()`.\n",
    "\n",
    "- We can use `KFold` function to split data into several training and validation sets.\n",
    "\n",
    "- **KFold() Function arguments**:\n",
    "    - **n_splits**: to specify the number of splits we want.\n",
    "    - **shuffle**: to specify whether we want the data to be shuffled.\n",
    "    - **random_state**: we can set a number if we want to replicate our results.\n",
    "\n",
    "- It is important to understand the principle of `KFold()` function, which returns the indexes of the data, not the data points themselves. `KFold` function creates a __generator__.\n",
    "- The `KFold` generator contains the indexes of the training and the validation data sets.\n",
    "\n",
    "- **KFold** is useful when we want to fit the same model several times. To do that,  If we need to use `for loop` to loop through the indexes of training and validation sets, then fit the required model.\n",
    "\n",
    "**Syntax**:\n",
    "\n",
    "```python \n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Create KFold generator\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=10123)\n",
    "\n",
    "# Create splits\n",
    "splits = kf.split(X)\n",
    "\n",
    "# Print the number of indices\n",
    "for train_index, val_index in splits:\n",
    "    print(\"Number of training indices: {:s}\".format(len(train_index))\n",
    "    print(\"Number of validation indices:{:s}\".format(len(val_index))\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1731369",
   "metadata": {},
   "source": [
    "### Priliminary Example of Using KFold\n",
    "\n",
    "We generate some data in order to show how this techniques works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b15c646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gen = np.arange(1, 51)\n",
    "y_gen = np.array([np.repeat(1, 25), np.repeat(2, 25)]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "529c77db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import KFold function\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce5ee58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 5 k-fold splites, whithout shuffling\n",
    "kf_order = KFold(n_splits = 5, shuffle = False)\n",
    "\n",
    "# Create splits\n",
    "splits = kf_order.split(X_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a839f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 10\n",
      "40 10\n",
      "40 10\n",
      "40 10\n",
      "40 10\n"
     ]
    }
   ],
   "source": [
    "# Print the number of indices\n",
    "for train_index, val_index in splits:\n",
    "    print(len(train_index), len(val_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "297815fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] [40 41 42 43 44 45 46 47 48 49]\n"
     ]
    }
   ],
   "source": [
    "# Print the indexes of one train_index and one val_index\n",
    "print(train_index, val_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6e083e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create 5 k-fold splites, whith shuffling\n",
    "kf_shuffle = KFold(n_splits = 5, shuffle = True, random_state = 10123)\n",
    "\n",
    "# Create splits\n",
    "splits_shuf = kf_shuffle.split(X_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d48b16d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 10\n",
      "40 10\n",
      "40 10\n",
      "40 10\n",
      "40 10\n"
     ]
    }
   ],
   "source": [
    "# Print the number of indices\n",
    "for train_index, val_index in splits_shuf:\n",
    "    print(len(train_index), len(val_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a168ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  5  6  7  8  9 10 12 16 17 18 19 21 22 23 24 25 26 27 31 32\n",
      " 33 34 35 36 37 38 39 40 42 43 44 45 46 47 48 49] [ 4 11 13 14 15 20 28 29 30 41]\n"
     ]
    }
   ],
   "source": [
    "# Print the indexes of one train_index and one val_index\n",
    "print(train_index, val_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56bb5d8",
   "metadata": {},
   "source": [
    "## K-Fold In Practice üî¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a07344e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KFold generator\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 10123)\n",
    "\n",
    "# Creatw Splits\n",
    "splits = kf.split(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f40692b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training indices: 404\n",
      "Number of validation indices: 102\n",
      "\n",
      "Number of training indices: 405\n",
      "Number of validation indices: 101\n",
      "\n",
      "Number of training indices: 405\n",
      "Number of validation indices: 101\n",
      "\n",
      "Number of training indices: 405\n",
      "Number of validation indices: 101\n",
      "\n",
      "Number of training indices: 405\n",
      "Number of validation indices: 101\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the number of indices\n",
    "for train_index, val_index in splits:\n",
    "    print('Number of training indices: {}'.format(len(train_index)))\n",
    "    print('Number of validation indices: {}'.format(len(val_index)), end = '\\n\\n')    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564d5d19",
   "metadata": {},
   "source": [
    "## Using sklearn to build regression model and metrics üß™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "486de5ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required tools\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "564479cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiation/create a LinearRegression object\n",
    "lreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd8a8fc",
   "metadata": {},
   "source": [
    "## Fitting Linear Regression ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9a63c93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit linear model\n",
    "lreg.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe565032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The MSE metric: 19.99443\n",
      "The MAE metric: 3.37722\n",
      "\n",
      "The MSE metric: 39.91115\n",
      "The MAE metric: 3.74241\n",
      "\n",
      "The MSE metric: 22.85837\n",
      "The MAE metric: 3.30429\n",
      "\n",
      "The MSE metric: 21.65831\n",
      "The MAE metric: 3.58502\n",
      "\n",
      "The MSE metric: 18.20975\n",
      "The MAE metric: 3.03346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create KFold generator\n",
    "kf = KFold(n_splits = 5, shuffle = True, random_state = 10123)\n",
    "\n",
    "# create splits\n",
    "splits = kf.split(X)\n",
    "\n",
    "# Access the training and validation indices of splits by using a for loop\n",
    "for train_index, val_index in splits:\n",
    "    \n",
    "    # Split the data into a train and a validation set\n",
    "    X_train, y_train = X[train_index], y[train_index]\n",
    "    X_test, y_test = X[val_index], y[val_index]\n",
    "    \n",
    "    # Fit a linear regression    \n",
    "    lreg.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions, and print mean squared error and mae\n",
    "    preds = lreg.predict(X_test)\n",
    "    print(\"The MSE metric: {:.5f}\".format(mean_squared_error(y_test, preds)))\n",
    "    print(\"The MAE metric: {:.5f}\".format(mean_absolute_error(y_test, preds)), end = '\\n\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52779be",
   "metadata": {},
   "source": [
    "## Automating K-fold Cross Validation with cross_val_score() Function\n",
    "\n",
    "- **KFold** function requires from us to use a `for loop`, which usually inefficient (we know that loops takes longer time). \n",
    "\n",
    "- Fortunately, sklearn has an automatic function to perform **k-fold cross validation**, which is __cross_val_score()__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c066a65",
   "metadata": {},
   "source": [
    "## Fitting Linear Regression Model Using Cross Validation\n",
    "\n",
    "As before, we use sklearn API. So, we need to import LinearRegression and instatiate an abject. \n",
    "\n",
    "From __sklearn.model_selection__ we import __cross_val_score__\n",
    "\n",
    "#### The cross_val_score() method parameters\n",
    "\n",
    "The cross_val_score() requires four parameters, and other several arguments, but we  talk about the required arguments here, and we will talk about other options in later lectures.\n",
    "  - **estimator**: the specific model to be used (linear regression in this lecture)\n",
    "  - **X**: the inputs of the complete training dataset.\n",
    "  - **y**: the complete values of the target variable.\n",
    "  - **cv**: the parameter cv allows us to specify the number of cross-validation splits (or folds).\n",
    "  \n",
    "Syntax:\n",
    "```python\n",
    "from sklear.model_selection import cross_val_score\n",
    "```\n",
    "\n",
    "### Performing Cross Validation\n",
    "\n",
    "  To perform cross validation, you need to pass a Linear Regression object, the features data, and the target data, finally you set the number of folds.\n",
    "  \n",
    "  - **cross_val_score** splits the data into k-folds and compute R^2 by default, and it returns an array of the R^2 metric. \n",
    "Syntax:\n",
    "```python\n",
    "cross_val_score(lreg, X, y, cv = k-folds (5 or 10 ...))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "18c06094",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_boston().data\n",
    "y = load_boston().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3a72bc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Linear Regression, and cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85b10f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiation/create a LinearRegression object\n",
    "lreg = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d80f0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform cross validation\n",
    "cv_results = cross_val_score(lreg, X, y, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c634fc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# print the type of CV results\n",
    "print(type(cv_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3bb16a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.63919994,  0.71386698,  0.58702344,  0.07923081, -0.25294154])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results  # The results is R^2  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "feb06a53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average R^2 is: 0.3533\n"
     ]
    }
   ],
   "source": [
    "# compute the average R^2\n",
    "avg_r_sq = np.mean(cv_results)\n",
    "print(f'The average R^2 is: {avg_r_sq :.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54432c88",
   "metadata": {},
   "source": [
    "This value is lower than the value we found in the train/test split technique (0.55).\n",
    "\n",
    "If we were to trust that model, we would be over optimistic about our model. \n",
    "\n",
    "This often leads poor performance of the model on unseen data; in other words, it does not generalize well. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf3cded",
   "metadata": {},
   "source": [
    "## Scoring The Cross Validation Results with Different Metrics üíØ\n",
    "\n",
    "- If you want to use a different scoring function, you can create a scorer by using the **make_scorer()** method from `sklearn.metrics`, then specify metric you'd like to use.\n",
    "\n",
    "- Set the **argument scoring** in `cross_val_score()` function the scorer you chosed.\n",
    "\n",
    "\n",
    "After scoring, report the mean of the metric used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67bced84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary tools for performing Cross Validation\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, make_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "df35dd3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiation/create a LinearRegression object\n",
    "lreg_cv = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c9795e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make mae scorer\n",
    "mae = make_scorer(mean_absolute_error)\n",
    "\n",
    "# perform 5-fold CV\n",
    "cv_res = cross_val_score(lreg_cv, X, y, cv = 5, scoring = mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "aee65e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.62190565, 3.90725478, 4.386606  , 5.57073637, 4.76333993])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3bc1d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.249968544192538\n"
     ]
    }
   ],
   "source": [
    "# Print the mean error\n",
    "print(cv_res.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "33b63546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make mse scorer\n",
    "mse = make_scorer(mean_squared_error)\n",
    "\n",
    "# perform 5-fold CV\n",
    "cv_res = cross_val_score(lreg_cv, X, y, cv = 5, scoring = mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8faa570f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12.46030057 26.04862111 33.07413798 80.76237112 33.31360656]\n"
     ]
    }
   ],
   "source": [
    "print(cv_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2891bc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.13180746769922\n"
     ]
    }
   ],
   "source": [
    "# Print the mean error\n",
    "print(cv_res.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717b5c0b",
   "metadata": {},
   "source": [
    "## Train / Validation / Test set \n",
    "\n",
    "- One approach to test different models and parameter sets is to split the data into training, validation, and testing datasets.\n",
    "\n",
    "- In order to split the data into training and testing datasets, firts we split the data into **two sets, temporary and train sets**, then we split the train set into  **validation set** and **train set**.\n",
    "\n",
    "- we `train_test_split()` function from sklearn to do the splitting. \n",
    "\n",
    "**Syntax**:\n",
    "\n",
    "```python\n",
    "# Create training and temporay sets. \n",
    "X_temp, X_test, y_temp, y_test  =\\\n",
    "             train_test_split(X, y,\n",
    "                              test_size= 0.15, \n",
    "                              random_state=10123)\n",
    "# Create validation and train sets\n",
    "X_train, X_val, y_train, y_val  =\\\n",
    "             train_test_split(X_temp, y_temp,\n",
    "                              test_size= 0.25, \n",
    "                              random_state=10123)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b726e586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import train_test_split\n",
    "from sklearn.model_selection import train_test_split \n",
    "# Create training and temporay sets. \n",
    "X_temp, X_test, y_temp, y_test  =\\\n",
    "             train_test_split(X, y,\n",
    "                              test_size= 0.15, \n",
    "                              random_state=10123)\n",
    "# Create validation and train sets\n",
    "X_train, X_val, y_train, y_val  =\\\n",
    "             train_test_split(X_temp, y_temp,\n",
    "                              test_size= 0.25, \n",
    "                              random_state=10123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26662edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(322, 13) (76, 13) (108, 13) (322,) (76,) (108,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shapes of the sets\n",
    "print(X_train.shape, X_test.shape, X_val.shape, y_train.shape,\\\n",
    "      y_test.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20071fd3",
   "metadata": {},
   "source": [
    "### When to use Train / Validation / Test Sets\n",
    "\n",
    "- It is important to understand when you would use three datasets (training, validation, and testing) instead of two (training and testing).\n",
    "\n",
    "- Three datasets are useful in many cases:\n",
    "   - When testing parameters.\n",
    "   - When Tuning hyper-parameters.\n",
    "   - When Frequently evaluate the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c4b0e5",
   "metadata": {},
   "source": [
    "__________________________________________________________________\n",
    "# <span style=\"color:Purple\">End The Project, *Thank you*</span> üîöü•Ä\n",
    "__________________________________________________________________"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
